{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNK7vbHo-KYU"
   },
   "source": [
    "## Bayesian methods of hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BlFdvPwF-KYW"
   },
   "source": [
    "In addition to the random search and the grid search methods for selecting optimal hyperparameters, we can use Bayesian methods of probabilities to select the optimal hyperparameters for an algorithm.\n",
    "\n",
    "In this case study, we will be using the BayesianOptimization library to perform hyperparmater tuning. This library has very good documentation which you can find here: https://github.com/fmfn/BayesianOptimization\n",
    "\n",
    "You will need to install the Bayesian optimization module. Running a cell with an exclamation point in the beginning of the command will run it as a shell command — please do this to install this module from our notebook in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pssx080d-Ulf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian_optimization-2.0.3-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp312-cp312-macosx_11_0_universal2.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.25 in /opt/anaconda3/lib/python3.12/site-packages (from bayesian-optimization) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from bayesian-optimization) (1.6.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from bayesian-optimization) (1.13.1)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly->catboost) (8.2.3)\n",
      "Downloading bayesian_optimization-2.0.3-py3-none-any.whl (31 kB)\n",
      "Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catboost-1.2.7-cp312-cp312-macosx_11_0_universal2.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, lightgbm, catboost, bayesian-optimization\n",
      "Successfully installed bayesian-optimization-2.0.3 catboost-1.2.7 graphviz-0.20.3 lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install bayesian-optimization lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T16:39:09.312682Z",
     "start_time": "2019-04-22T16:39:09.309208Z"
    },
    "_kg_hide-input": true,
    "colab": {},
    "colab_type": "code",
    "id": "l9nfFTyj-KYY"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from bayes_opt import BayesianOptimization\n",
    "from catboost import CatBoostClassifier, cv, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "D16Dquw1AAK0",
    "outputId": "44167587-f22e-4bf5-a816-e2bcfdc6c4ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bayesian_optimization_case_study.ipynb', '.ipynb_checkpoints', 'data']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T14:48:15.929012Z",
     "start_time": "2019-04-22T14:48:15.926574Z"
    },
    "colab_type": "text",
    "id": "AkBt3yds-KYu"
   },
   "source": [
    "## How does Bayesian optimization work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1kyBCUs-KYv"
   },
   "source": [
    "Bayesian optimization works by constructing a posterior distribution of functions (Gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not, as seen in the picture below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAdHF72R-KYw"
   },
   "source": [
    "<img src=\"https://github.com/fmfn/BayesianOptimization/blob/master/examples/bo_example.png?raw=true\" />\n",
    "As you iterate over and over, the algorithm balances its needs of exploration and exploitation while taking into account what it knows about the target function. At each step, a Gaussian Process is fitted to the known samples (points previously explored), and the posterior distribution, combined with an exploration strategy (such as UCB — aka Upper Confidence Bound), or EI (Expected Improvement). This process is used to determine the next point that should be explored (see the gif below).\n",
    "<img src=\"https://github.com/fmfn/BayesianOptimization/raw/master/examples/bayesian_optimization.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTP8KUlLoYzu"
   },
   "source": [
    "## Let's look at a simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crpPqKdC-KYx"
   },
   "source": [
    "The first step is to create an optimizer. It uses two items:\n",
    "* function to optimize\n",
    "* bounds of parameters\n",
    "\n",
    "The function is the procedure that counts metrics of our model quality. The important thing is that our optimization will maximize the value on function. Smaller metrics are best. Hint: don't forget to use negative metric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e09ciF8gpTfr"
   },
   "source": [
    "Here we define our simple function we want to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofwvnfEwo5mG"
   },
   "outputs": [],
   "source": [
    "def simple_func(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCGsdciCpeI3"
   },
   "source": [
    "Now, we define our bounds of the parameters to optimize, within the Bayesian optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jLYW2qnpOFr"
   },
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    simple_func,\n",
    "    {'a': (1, 3),\n",
    "    'b': (4, 7)}\n",
    "    ,random_state=42  # Ensures repeatability\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dg6LdYx8pq2T"
   },
   "source": [
    "These are the main parameters of this function:\n",
    "\n",
    "* **n_iter:** This is how many steps of Bayesian optimization you want to perform. The more steps, the more likely you are to find a good maximum.\n",
    "\n",
    "* **init_points:** This is how many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-GKMJ1uqMYv"
   },
   "source": [
    "Let's run an example where we use the optimizer to find the best values to maximize the target value for a and b given the inputs of 3 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Oy44Ro7wqNat",
    "outputId": "9cc64d54-b1e6-46d1-dc29-4c0039a1c72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     a     |     b     |\n",
      "-------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m8.601    \u001b[39m | \u001b[39m1.749    \u001b[39m | \u001b[39m6.852    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m8.26     \u001b[39m | \u001b[39m2.464    \u001b[39m | \u001b[39m5.796    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m5.78     \u001b[39m | \u001b[39m1.312    \u001b[39m | \u001b[39m4.468    \u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m9.802    \u001b[39m | \u001b[35m2.822    \u001b[39m | \u001b[35m6.979    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m9.603    \u001b[39m | \u001b[39m2.996    \u001b[39m | \u001b[39m6.607    \u001b[39m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyKFMF2Hq2Sx"
   },
   "source": [
    "Great, now let's print the best parameters and the associated maximized target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_H6DixyfscV_",
    "outputId": "fd0c35d7-e30d-4d30-9ab2-12c0fa837971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 2.82203139995844, 'b': 6.979491216800435}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.801522616758875"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(optimizer.max['params']);optimizer.max['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQ1T1V6Mspi4"
   },
   "source": [
    "## Test it on real data using the Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_oGwREZkm4h"
   },
   "source": [
    "The dataset we will be working with is the famous flight departures dataset. Our modeling goal will be to predict if a flight departure is going to be delayed by 15 minutes based on the other attributes in our dataset. As part of this modeling exercise, we will use Bayesian hyperparameter optimization to identify the best parameters for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abYSagjQANDZ"
   },
   "source": [
    "**<font color='teal'> You can load the zipped csv files just as you would regular csv files using Pandas read_csv. In the next cell load the train and test data into two seperate dataframes. </font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWKBApVuAeJe"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/shivanginimarjiwe/Desktop/repo/DataScienceGuidedCapstone/18.2.6 - Bayesian Optimization/data/flight_delays_train.csv')\n",
    "\n",
    "test_df = pd.read_csv('/Users/shivanginimarjiwe/Desktop/repo/DataScienceGuidedCapstone/18.2.6 - Bayesian Optimization/data/flight_delays_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OapNcT9Eikis"
   },
   "source": [
    "**<font color='teal'> Print the top five rows of the train dataframe and review the columns in the data. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "__4cXZ8iiYaC",
    "outputId": "8718ad4b-8955-486c-9ae8-1dee6aa6c2fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n",
       "0   c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n",
       "1   c-4       c-20       c-3     1548            US    PIT  MCO       834   \n",
       "2   c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n",
       "3  c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n",
       "4  c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n",
       "\n",
       "  dep_delayed_15min  \n",
       "0                 N  \n",
       "1                 N  \n",
       "2                 N  \n",
       "3                 N  \n",
       "4                 Y  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation :\n",
    "\n",
    "It looks like some categorical features (Month, DayofMonth, DayOfWeek) are still encoded with prefixes like c-8, c-21, etc., \n",
    "rather than numerical values. This means they were not properly transformed during the preprocessing step.\n",
    "\n",
    "Fixing the Encoding:\n",
    "1. These values appear to be categorical but should be converted into numerical labels.\n",
    "2. Reprocess these columns correctly before moving on to Bayesian Optimization with LightGBM.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1934</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>78</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1548</td>\n",
       "      <td>18</td>\n",
       "      <td>217</td>\n",
       "      <td>171</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1422</td>\n",
       "      <td>20</td>\n",
       "      <td>228</td>\n",
       "      <td>59</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1015</td>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "      <td>175</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>1828</td>\n",
       "      <td>19</td>\n",
       "      <td>174</td>\n",
       "      <td>199</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  DayofMonth  DayOfWeek  DepTime  UniqueCarrier  Origin  Dest  \\\n",
       "0     10          13          6     1934              0      18    78   \n",
       "1      6          12          2     1548             18     217   171   \n",
       "2     11          11          4     1422             20     228    59   \n",
       "3      2          17          5     1015             15      78   175   \n",
       "4      1          28          5     1828             19     174   199   \n",
       "\n",
       "   Distance  \n",
       "0       732  \n",
       "1       834  \n",
       "2       416  \n",
       "3       872  \n",
       "4       423  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use category encoding with mapping for unseen labels\n",
    "for col in ['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest']:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "    \n",
    "    # Create a mapping of known values\n",
    "    mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    \n",
    "    # Apply mapping to test data, assigning -1 for unknown categories\n",
    "    test_df[col] = test_df[col].map(lambda x: mapping.get(x, -1))\n",
    "\n",
    "# Encode target variable\n",
    "train_df['dep_delayed_15min'] = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop(columns=['dep_delayed_15min'])\n",
    "y_train = train_df['dep_delayed_15min']\n",
    "X_test = test_df  # No target column in test set\n",
    "\n",
    "# Display processed dataset\n",
    "X_train.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset has been successfully preprocessed, with categorical columns encoded properly and \n",
    "#the target variable transformed into binary format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UxGBsPQhffgd"
   },
   "source": [
    "**<font color='teal'> Use the describe function to review the numeric columns in the train dataframe. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "_bRRKG3DAtae",
    "outputId": "7cfb9975-ec97-422c-abbd-98923a0b7aec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.562110</td>\n",
       "      <td>14.823920</td>\n",
       "      <td>2.95183</td>\n",
       "      <td>1341.523880</td>\n",
       "      <td>12.045040</td>\n",
       "      <td>142.37781</td>\n",
       "      <td>141.041110</td>\n",
       "      <td>729.39716</td>\n",
       "      <td>0.19044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.451188</td>\n",
       "      <td>8.952739</td>\n",
       "      <td>1.99164</td>\n",
       "      <td>476.378445</td>\n",
       "      <td>6.566272</td>\n",
       "      <td>76.89900</td>\n",
       "      <td>76.783888</td>\n",
       "      <td>574.61686</td>\n",
       "      <td>0.39265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>931.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>317.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1330.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>151.00000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>575.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1733.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>205.00000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>957.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>2534.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>288.00000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>4962.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Month     DayofMonth     DayOfWeek        DepTime  \\\n",
       "count  100000.000000  100000.000000  100000.00000  100000.000000   \n",
       "mean        5.562110      14.823920       2.95183    1341.523880   \n",
       "std         3.451188       8.952739       1.99164     476.378445   \n",
       "min         0.000000       0.000000       0.00000       1.000000   \n",
       "25%         3.000000       7.000000       1.00000     931.000000   \n",
       "50%         6.000000      15.000000       3.00000    1330.000000   \n",
       "75%         9.000000      22.000000       5.00000    1733.000000   \n",
       "max        11.000000      30.000000       6.00000    2534.000000   \n",
       "\n",
       "       UniqueCarrier        Origin           Dest      Distance  \\\n",
       "count  100000.000000  100000.00000  100000.000000  100000.00000   \n",
       "mean       12.045040     142.37781     141.041110     729.39716   \n",
       "std         6.566272      76.89900      76.783888     574.61686   \n",
       "min         0.000000       0.00000       0.000000      30.00000   \n",
       "25%         6.000000      78.00000      77.000000     317.00000   \n",
       "50%        13.000000     151.00000     150.000000     575.00000   \n",
       "75%        18.000000     205.00000     203.000000     957.00000   \n",
       "max        21.000000     288.00000     288.000000    4962.00000   \n",
       "\n",
       "       dep_delayed_15min  \n",
       "count       100000.00000  \n",
       "mean             0.19044  \n",
       "std              0.39265  \n",
       "min              0.00000  \n",
       "25%              0.00000  \n",
       "50%              0.00000  \n",
       "75%              0.00000  \n",
       "max              1.00000  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5540      631\n",
       "40968     701\n",
       "53611    1309\n",
       "29243    1313\n",
       "89782    1443\n",
       "56715    1612\n",
       "23897    1633\n",
       "22385    1745\n",
       "23492    1956\n",
       "91560    2133\n",
       "Name: DepTime, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display unique sample values of DepTime to analyze its format\n",
    "train_df['DepTime'].sample(10).sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation \n",
    "\n",
    "The current DepTime is in HHMM format.\n",
    "we Need to convert it into 2400 hours format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepTime</th>\n",
       "      <th>DepTime_24000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934</td>\n",
       "      <td>80.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1548</td>\n",
       "      <td>64.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1422</td>\n",
       "      <td>59.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015</td>\n",
       "      <td>42.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1828</td>\n",
       "      <td>76.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1918</td>\n",
       "      <td>79.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>754</td>\n",
       "      <td>31.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>635</td>\n",
       "      <td>26.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>735</td>\n",
       "      <td>30.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2029</td>\n",
       "      <td>84.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepTime  DepTime_24000\n",
       "0     1934      80.583333\n",
       "1     1548      64.500000\n",
       "2     1422      59.250000\n",
       "3     1015      42.291667\n",
       "4     1828      76.166667\n",
       "5     1918      79.916667\n",
       "6      754      31.416667\n",
       "7      635      26.458333\n",
       "8      735      30.625000\n",
       "9     2029      84.541667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert DepTime to 24,000-hour format\n",
    "train_df['DepTime_24000'] = train_df['DepTime'] / 24\n",
    "test_df['DepTime_24000'] = test_df['DepTime'] / 24\n",
    "\n",
    "# Display the transformed DepTime column\n",
    "display(train_df[['DepTime', 'DepTime_24000']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6k-_fI5Aiyh"
   },
   "source": [
    "Notice, `DepTime` is the departure time in a numeric representation in 2400 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation:\n",
    "\n",
    "Yes. Now we have converted the Deptime into 2400 hours format. This conversion ensures DepTime is on a normalized scale, \n",
    "making it easier for the model to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtZS4-hrlQah"
   },
   "source": [
    " **<font color='teal'>The response variable is 'dep_delayed_15min' which is a categorical column, so we need to map the Y for yes and N for no values to 1 and 0. Run the code in the next cell to do this.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:38:42.677690Z",
     "start_time": "2019-04-22T15:38:42.481963Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yRlOTbnW-KYc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_df = train_df[train_df.DepTime <= 2400].copy()\n",
    "#y_train = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\n",
    "\n",
    "# Ensure only valid DepTime values (<= 2400) are used\n",
    "train_df = train_df[train_df.DepTime <= 2400].copy()\n",
    "\n",
    "# Convert target variable 'dep_delayed_15min' to binary (1 = 'Y', 0 = 'N')\n",
    "y_train = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\n",
    "\n",
    "# Display the first few values of the target variable\n",
    "display(y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation:\n",
    "\n",
    "The NaN values in y_train suggest that there might be an issue with the mapping process.\n",
    "\n",
    "Possible Reasons for NaN Values:\n",
    "The dep_delayed_15min column may contain unexpected values (not just \"Y\" and \"N\").\n",
    "The train_df may have missing values in dep_delayed_15min.\n",
    "\n",
    "Fix:\n",
    "First encode dep_delayed_15min.\n",
    "Then filter DepTime correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), 0, array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore the original train_df without filtering first\n",
    "train_df = pd.read_csv('/Users/shivanginimarjiwe/Desktop/repo/DataScienceGuidedCapstone/18.2.6 - Bayesian Optimization/data/flight_delays_train.csv')\n",
    "\n",
    "# Encode the target variable before filtering\n",
    "train_df['dep_delayed_15min'] = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Now filter the dataset for valid DepTime values\n",
    "train_df = train_df[train_df.DepTime <= 2400].copy()\n",
    "\n",
    "# Extract the target variable again\n",
    "y_train = train_df['dep_delayed_15min'].values\n",
    "\n",
    "# Display unique values and first few entries\n",
    "(unique_values_fixed, missing_values_fixed) = (train_df['dep_delayed_15min'].unique(), train_df['dep_delayed_15min'].isnull().sum())\n",
    "\n",
    "(unique_values_fixed, missing_values_fixed, y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Issue fixed :\n",
    "\n",
    "Unique values in dep_delayed_15min are now [0, 1] (correctly encoded).\n",
    "No missing values in dep_delayed_15min (missing_values = 0).\n",
    "First few values of y_train: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] (correctly mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3WPkFQO9uo9"
   },
   "source": [
    "## Feature Engineering\n",
    "Use these defined functions to create additional features for the model. Run the cell to add the functions to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXqsqz5W9t3r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions have been added to the workspace.\n"
     ]
    }
   ],
   "source": [
    "def label_enc(df_column):\n",
    "    df_column = LabelEncoder().fit_transform(df_column)\n",
    "    return df_column\n",
    "\n",
    "def make_harmonic_features_sin(value, period=2400):\n",
    "    value *= 2 * np.pi / period \n",
    "    return np.sin(value)\n",
    "\n",
    "def make_harmonic_features_cos(value, period=2400):\n",
    "    value *= 2 * np.pi / period \n",
    "    return np.cos(value)\n",
    "\n",
    "def feature_eng(df):\n",
    "    df['flight'] = df['Origin']+df['Dest']\n",
    "    df['Month'] = df.Month.map(lambda x: x.split('-')[-1]).astype('int32')\n",
    "    df['DayofMonth'] = df.DayofMonth.map(lambda x: x.split('-')[-1]).astype('uint8')\n",
    "    df['begin_of_month'] = (df['DayofMonth'] < 10).astype('uint8')\n",
    "    df['midddle_of_month'] = ((df['DayofMonth'] >= 10)&(df['DayofMonth'] < 20)).astype('uint8')\n",
    "    df['end_of_month'] = (df['DayofMonth'] >= 20).astype('uint8')\n",
    "    df['DayOfWeek'] = df.DayOfWeek.map(lambda x: x.split('-')[-1]).astype('uint8')\n",
    "    df['hour'] = df.DepTime.map(lambda x: x/100).astype('int32')\n",
    "    df['morning'] = df['hour'].map(lambda x: 1 if (x <= 11)& (x >= 7) else 0).astype('uint8')\n",
    "    df['day'] = df['hour'].map(lambda x: 1 if (x >= 12) & (x <= 18) else 0).astype('uint8')\n",
    "    df['evening'] = df['hour'].map(lambda x: 1 if (x >= 19) & (x <= 23) else 0).astype('uint8')\n",
    "    df['night'] = df['hour'].map(lambda x: 1 if (x >= 0) & (x <= 6) else 0).astype('int32')\n",
    "    df['winter'] = df['Month'].map(lambda x: x in [12, 1, 2]).astype('int32')\n",
    "    df['spring'] = df['Month'].map(lambda x: x in [3, 4, 5]).astype('int32')\n",
    "    df['summer'] = df['Month'].map(lambda x: x in [6, 7, 8]).astype('int32')\n",
    "    df['autumn'] = df['Month'].map(lambda x: x in [9, 10, 11]).astype('int32')\n",
    "    df['holiday'] = (df['DayOfWeek'] >= 5).astype(int) \n",
    "    df['weekday'] = (df['DayOfWeek'] < 5).astype(int)\n",
    "    df['airport_dest_per_month'] = df.groupby(['Dest', 'Month'])['Dest'].transform('count')\n",
    "    df['airport_origin_per_month'] = df.groupby(['Origin', 'Month'])['Origin'].transform('count')\n",
    "    df['airport_dest_count'] = df.groupby(['Dest'])['Dest'].transform('count')\n",
    "    df['airport_origin_count'] = df.groupby(['Origin'])['Origin'].transform('count')\n",
    "    df['carrier_count'] = df.groupby(['UniqueCarrier'])['Dest'].transform('count')\n",
    "    df['carrier_count_per month'] = df.groupby(['UniqueCarrier', 'Month'])['Dest'].transform('count')\n",
    "    df['deptime_cos'] = df['DepTime'].map(make_harmonic_features_cos)\n",
    "    df['deptime_sin'] = df['DepTime'].map(make_harmonic_features_sin)\n",
    "    df['flightUC'] = df['flight']+df['UniqueCarrier']\n",
    "    df['DestUC'] = df['Dest']+df['UniqueCarrier']\n",
    "    df['OriginUC'] = df['Origin']+df['UniqueCarrier']\n",
    "    return df.drop('DepTime', axis=1)\n",
    "\n",
    "# Functions are now ready for use!\n",
    "print(\"Feature engineering functions have been added to the workspace.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BYbxXpU-FGE"
   },
   "source": [
    "Concatenate the training and testing dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cj6bfSNw_RAf"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m full_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([train_df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdep_delayed_15min\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), test_df])\n\u001b[0;32m----> 2\u001b[0m full_df \u001b[38;5;241m=\u001b[39m feature_eng(full_df)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the transformed dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m display(full_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[142], line 15\u001b[0m, in \u001b[0;36mfeature_eng\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_eng\u001b[39m(df):\n\u001b[1;32m     14\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrigin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mMonth\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDayofMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mDayofMonth\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbegin_of_month\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDayofMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4700\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[1;32m   4621\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4622\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   4623\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4624\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4626\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4627\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4698\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4700\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_values(arg, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m   4701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4702\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4703\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[142], line 15\u001b[0m, in \u001b[0;36mfeature_eng.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_eng\u001b[39m(df):\n\u001b[1;32m     14\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrigin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mMonth\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDayofMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mDayofMonth\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbegin_of_month\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDayofMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "full_df = pd.concat([train_df.drop('dep_delayed_15min', axis=1), test_df])\n",
    "full_df = feature_eng(full_df)\n",
    "\n",
    "# Display the first few rows of the transformed dataset\n",
    "display(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Error Fix:\n",
    "\n",
    "We need to properly extract the numeric part of these columns before converting them to integers.\n",
    "Instead of  \" df['Month'] = df['Month'].astype('int32')\"  we need to use \n",
    "\"df['Month'] = df['Month'].str.split('-').str[-1].astype('int32')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DepTime_24000</th>\n",
       "      <th>flight</th>\n",
       "      <th>begin_of_month</th>\n",
       "      <th>...</th>\n",
       "      <th>airport_origin_per_month</th>\n",
       "      <th>airport_dest_count</th>\n",
       "      <th>airport_origin_count</th>\n",
       "      <th>carrier_count</th>\n",
       "      <th>carrier_count_per_month</th>\n",
       "      <th>deptime_cos</th>\n",
       "      <th>deptime_sin</th>\n",
       "      <th>flightUC</th>\n",
       "      <th>DestUC</th>\n",
       "      <th>OriginUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATLDFW</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>534</td>\n",
       "      <td>4337</td>\n",
       "      <td>5822</td>\n",
       "      <td>9418</td>\n",
       "      <td>789</td>\n",
       "      <td>0.343660</td>\n",
       "      <td>-0.939094</td>\n",
       "      <td>ATLDFWAA</td>\n",
       "      <td>DFWAA</td>\n",
       "      <td>ATLAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PITMCO</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>1728</td>\n",
       "      <td>688</td>\n",
       "      <td>6482</td>\n",
       "      <td>537</td>\n",
       "      <td>-0.612907</td>\n",
       "      <td>-0.790155</td>\n",
       "      <td>PITMCOUS</td>\n",
       "      <td>MCOUS</td>\n",
       "      <td>PITUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDUCLE</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>1217</td>\n",
       "      <td>868</td>\n",
       "      <td>5901</td>\n",
       "      <td>493</td>\n",
       "      <td>-0.835807</td>\n",
       "      <td>-0.549023</td>\n",
       "      <td>RDUCLEXE</td>\n",
       "      <td>CLEXE</td>\n",
       "      <td>RDUXE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DENMEM</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>629</td>\n",
       "      <td>2973</td>\n",
       "      <td>7390</td>\n",
       "      <td>567</td>\n",
       "      <td>-0.884988</td>\n",
       "      <td>0.465615</td>\n",
       "      <td>DENMEMOO</td>\n",
       "      <td>MEMOO</td>\n",
       "      <td>DENOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDWOMA</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>311</td>\n",
       "      <td>1366</td>\n",
       "      <td>15082</td>\n",
       "      <td>1358</td>\n",
       "      <td>0.073238</td>\n",
       "      <td>-0.997314</td>\n",
       "      <td>MDWOMAWN</td>\n",
       "      <td>OMAWN</td>\n",
       "      <td>MDWWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  DayofMonth  DayOfWeek UniqueCarrier Origin Dest  Distance  \\\n",
       "0      8          21          7            AA    ATL  DFW       732   \n",
       "1      4          20          3            US    PIT  MCO       834   \n",
       "2      9           2          5            XE    RDU  CLE       416   \n",
       "3     11          25          6            OO    DEN  MEM       872   \n",
       "4     10           7          6            WN    MDW  OMA       423   \n",
       "\n",
       "   DepTime_24000  flight  begin_of_month  ...  airport_origin_per_month  \\\n",
       "0            NaN  ATLDFW               0  ...                       534   \n",
       "1            NaN  PITMCO               0  ...                        42   \n",
       "2            NaN  RDUCLE               1  ...                        59   \n",
       "3            NaN  DENMEM               0  ...                       250   \n",
       "4            NaN  MDWOMA               1  ...                       121   \n",
       "\n",
       "   airport_dest_count  airport_origin_count  carrier_count  \\\n",
       "0                4337                  5822           9418   \n",
       "1                1728                   688           6482   \n",
       "2                1217                   868           5901   \n",
       "3                 629                  2973           7390   \n",
       "4                 311                  1366          15082   \n",
       "\n",
       "   carrier_count_per_month  deptime_cos  deptime_sin  flightUC  DestUC  \\\n",
       "0                      789     0.343660    -0.939094  ATLDFWAA   DFWAA   \n",
       "1                      537    -0.612907    -0.790155  PITMCOUS   MCOUS   \n",
       "2                      493    -0.835807    -0.549023  RDUCLEXE   CLEXE   \n",
       "3                      567    -0.884988     0.465615  DENMEMOO   MEMOO   \n",
       "4                     1358     0.073238    -0.997314  MDWOMAWN   OMAWN   \n",
       "\n",
       "   OriginUC  \n",
       "0     ATLAA  \n",
       "1     PITUS  \n",
       "2     RDUXE  \n",
       "3     DENOO  \n",
       "4     MDWWN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify the feature_eng function to correctly extract numeric values from categorical columns\n",
    "def feature_eng_fixed(df):\n",
    "    \"\"\"Applies feature engineering transformations with correct handling of categorical formats.\"\"\"\n",
    "    \n",
    "    df = df.copy()  # Work on a copy to prevent modification of the original data\n",
    "    \n",
    "    df['flight'] = df['Origin'] + df['Dest']\n",
    "    \n",
    "    # Extract numeric values from encoded categorical features (handling 'c-8' format)\n",
    "    df['Month'] = df['Month'].astype(str).str.split('-').str[-1].astype('int32')\n",
    "    df['DayofMonth'] = df['DayofMonth'].astype(str).str.split('-').str[-1].astype('uint8')\n",
    "    df['begin_of_month'] = (df['DayofMonth'] < 10).astype('uint8')\n",
    "    df['midddle_of_month'] = ((df['DayofMonth'] >= 10) & (df['DayofMonth'] < 20)).astype('uint8')\n",
    "    df['end_of_month'] = (df['DayofMonth'] >= 20).astype('uint8')\n",
    "    df['DayOfWeek'] = df['DayOfWeek'].astype(str).str.split('-').str[-1].astype('uint8')\n",
    "    \n",
    "    # Extract hour from DepTime (assuming it's in HHMM format)\n",
    "    df['hour'] = (df.DepTime / 100).astype('int32')\n",
    "\n",
    "    # Time of day categories\n",
    "    df['morning'] = df['hour'].map(lambda x: 1 if (7 <= x <= 11) else 0).astype('uint8')\n",
    "    df['day'] = df['hour'].map(lambda x: 1 if (12 <= x <= 18) else 0).astype('uint8')\n",
    "    df['evening'] = df['hour'].map(lambda x: 1 if (19 <= x <= 23) else 0).astype('uint8')\n",
    "    df['night'] = df['hour'].map(lambda x: 1 if (0 <= x <= 6) else 0).astype('int32')\n",
    "\n",
    "    # Seasonal categories\n",
    "    df['winter'] = df['Month'].map(lambda x: 1 if x in [12, 1, 2] else 0).astype('int32')\n",
    "    df['spring'] = df['Month'].map(lambda x: 1 if x in [3, 4, 5] else 0).astype('int32')\n",
    "    df['summer'] = df['Month'].map(lambda x: 1 if x in [6, 7, 8] else 0).astype('int32')\n",
    "    df['autumn'] = df['Month'].map(lambda x: 1 if x in [9, 10, 11] else 0).astype('int32')\n",
    "\n",
    "    # Weekend and weekday flags\n",
    "    df['holiday'] = (df['DayOfWeek'] >= 5).astype(int) \n",
    "    df['weekday'] = (df['DayOfWeek'] < 5).astype(int)\n",
    "\n",
    "    # Group-based aggregations\n",
    "    df['airport_dest_per_month'] = df.groupby(['Dest', 'Month'])['Dest'].transform('count')\n",
    "    df['airport_origin_per_month'] = df.groupby(['Origin', 'Month'])['Origin'].transform('count')\n",
    "    df['airport_dest_count'] = df.groupby(['Dest'])['Dest'].transform('count')\n",
    "    df['airport_origin_count'] = df.groupby(['Origin'])['Origin'].transform('count')\n",
    "    df['carrier_count'] = df.groupby(['UniqueCarrier'])['Dest'].transform('count')\n",
    "    df['carrier_count_per_month'] = df.groupby(['UniqueCarrier', 'Month'])['Dest'].transform('count')\n",
    "\n",
    "    # Harmonic features for cyclic time variables\n",
    "    df['deptime_cos'] = df['DepTime'].map(make_harmonic_features_cos)\n",
    "    df['deptime_sin'] = df['DepTime'].map(make_harmonic_features_sin)\n",
    "\n",
    "    # Additional combined categorical features\n",
    "    df['flightUC'] = df['flight'] + df['UniqueCarrier']\n",
    "    df['DestUC'] = df['Dest'] + df['UniqueCarrier']\n",
    "    df['OriginUC'] = df['Origin'] + df['UniqueCarrier']\n",
    "\n",
    "    return df.drop('DepTime', axis=1)  # Drop the original DepTime column after transformation\n",
    "\n",
    "# Reapply feature engineering with the corrected function\n",
    "full_df = feature_eng_fixed(full_df)\n",
    "\n",
    "# Display the first few rows of the transformed dataset\n",
    "display(full_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GSO8JbfM_W-F"
   },
   "source": [
    "Apply the earlier defined feature engineering functions to the full dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6RfAINftjwi"
   },
   "outputs": [],
   "source": [
    "for column in ['UniqueCarrier', 'Origin', 'Dest','flight',  'flightUC', 'DestUC', 'OriginUC']:\n",
    "    full_df[column] = label_enc(full_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fix:\n",
    "Before applying Label Encoding, we need to:\n",
    "\n",
    "Convert all values in these columns to strings to ensure uniformity.\n",
    "Then apply Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DepTime_24000</th>\n",
       "      <th>flight</th>\n",
       "      <th>begin_of_month</th>\n",
       "      <th>...</th>\n",
       "      <th>airport_origin_per_month</th>\n",
       "      <th>airport_dest_count</th>\n",
       "      <th>airport_origin_count</th>\n",
       "      <th>carrier_count</th>\n",
       "      <th>carrier_count_per_month</th>\n",
       "      <th>deptime_cos</th>\n",
       "      <th>deptime_sin</th>\n",
       "      <th>flightUC</th>\n",
       "      <th>DestUC</th>\n",
       "      <th>OriginUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>301</td>\n",
       "      <td>359</td>\n",
       "      <td>732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>664</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>534</td>\n",
       "      <td>4337</td>\n",
       "      <td>5822</td>\n",
       "      <td>9418</td>\n",
       "      <td>789</td>\n",
       "      <td>0.343660</td>\n",
       "      <td>-0.939094</td>\n",
       "      <td>743</td>\n",
       "      <td>741</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>500</td>\n",
       "      <td>452</td>\n",
       "      <td>834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4039</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>1728</td>\n",
       "      <td>688</td>\n",
       "      <td>6482</td>\n",
       "      <td>537</td>\n",
       "      <td>-0.612907</td>\n",
       "      <td>-0.790155</td>\n",
       "      <td>6363</td>\n",
       "      <td>1259</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>511</td>\n",
       "      <td>340</td>\n",
       "      <td>416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4131</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>1217</td>\n",
       "      <td>868</td>\n",
       "      <td>5901</td>\n",
       "      <td>493</td>\n",
       "      <td>-0.835807</td>\n",
       "      <td>-0.549023</td>\n",
       "      <td>6493</td>\n",
       "      <td>619</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>361</td>\n",
       "      <td>456</td>\n",
       "      <td>872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>629</td>\n",
       "      <td>2973</td>\n",
       "      <td>7390</td>\n",
       "      <td>567</td>\n",
       "      <td>-0.884988</td>\n",
       "      <td>0.465615</td>\n",
       "      <td>2454</td>\n",
       "      <td>1293</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>457</td>\n",
       "      <td>480</td>\n",
       "      <td>423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3193</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>311</td>\n",
       "      <td>1366</td>\n",
       "      <td>15082</td>\n",
       "      <td>1358</td>\n",
       "      <td>0.073238</td>\n",
       "      <td>-0.997314</td>\n",
       "      <td>4915</td>\n",
       "      <td>1464</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  DayofMonth  DayOfWeek  UniqueCarrier  Origin  Dest  Distance  \\\n",
       "0      8          21          7             20     301   359       732   \n",
       "1      4          20          3             38     500   452       834   \n",
       "2      9           2          5             40     511   340       416   \n",
       "3     11          25          6             35     361   456       872   \n",
       "4     10           7          6             39     457   480       423   \n",
       "\n",
       "   DepTime_24000  flight  begin_of_month  ...  airport_origin_per_month  \\\n",
       "0            NaN     664               0  ...                       534   \n",
       "1            NaN    4039               0  ...                        42   \n",
       "2            NaN    4131               1  ...                        59   \n",
       "3            NaN    1693               0  ...                       250   \n",
       "4            NaN    3193               1  ...                       121   \n",
       "\n",
       "   airport_dest_count  airport_origin_count  carrier_count  \\\n",
       "0                4337                  5822           9418   \n",
       "1                1728                   688           6482   \n",
       "2                1217                   868           5901   \n",
       "3                 629                  2973           7390   \n",
       "4                 311                  1366          15082   \n",
       "\n",
       "   carrier_count_per_month  deptime_cos  deptime_sin  flightUC  DestUC  \\\n",
       "0                      789     0.343660    -0.939094       743     741   \n",
       "1                      537    -0.612907    -0.790155      6363    1259   \n",
       "2                      493    -0.835807    -0.549023      6493     619   \n",
       "3                      567    -0.884988     0.465615      2454    1293   \n",
       "4                     1358     0.073238    -0.997314      4915    1464   \n",
       "\n",
       "   OriginUC  \n",
       "0       361  \n",
       "1      1579  \n",
       "2      1646  \n",
       "3       732  \n",
       "4      1271  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure all values in categorical columns are strings before encoding\n",
    "for column in ['UniqueCarrier', 'Origin', 'Dest', 'flight', 'flightUC', 'DestUC', 'OriginUC']:\n",
    "    full_df[column] = full_df[column].astype(str)  # Convert to string\n",
    "    full_df[column] = label_enc(full_df[column])  # Apply Label Encoding\n",
    "\n",
    "# Display the first few rows of the updated dataset\n",
    "display(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The categorical columns have been successfully converted to strings and label-encoded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJAw1RGB_ZuM"
   },
   "source": [
    "\n",
    "Split the new full dataframe into X_train and X_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15cPtQU5tjfz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99983, 34), (100000, 34))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = full_df[:train_df.shape[0]]\n",
    "X_test = full_df[train_df.shape[0]:]\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "umfAw-9JErLV"
   },
   "source": [
    "Create a list of the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T14:31:58.412296Z",
     "start_time": "2019-04-22T14:31:58.409088Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5ibeVyNb-KZI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Month',\n",
       " 'DayOfWeek',\n",
       " 'UniqueCarrier',\n",
       " 'Origin',\n",
       " 'Dest',\n",
       " 'flight',\n",
       " 'flightUC',\n",
       " 'DestUC',\n",
       " 'OriginUC']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['Month',  'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest','flight',  'flightUC', 'DestUC', 'OriginUC']\n",
    "\n",
    "# Display the categorical features list\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzMIsMPIETVk"
   },
   "source": [
    "Let's build a light GBM model to test the bayesian optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:18:04.466965Z",
     "start_time": "2019-04-22T15:18:04.457992Z"
    },
    "colab_type": "text",
    "id": "2hfm1i5G-KZH"
   },
   "source": [
    "### [LightGBM](https://lightgbm.readthedocs.io/en/latest/) is a gradient boosting framework that uses tree-based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n",
    "\n",
    "* Faster training speed and higher efficiency.\n",
    "* Lower memory usage.\n",
    "* Better accuracy.\n",
    "* Support of parallel and GPU learning.\n",
    "* Capable of handling large-scale data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jf-3F2Wg-KZL"
   },
   "source": [
    "First, we define the function we want to maximize and that will count cross-validation metrics of lightGBM for our parameters.\n",
    "\n",
    "Some params such as num_leaves, max_depth, min_child_samples, min_data_in_leaf should be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:40:14.034265Z",
     "start_time": "2019-04-22T15:40:14.027868Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "LyUJBhGX-KZM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM evaluation function is ready.\n"
     ]
    }
   ],
   "source": [
    "def lgb_eval(num_leaves,max_depth,lambda_l2,lambda_l1,min_child_samples, min_data_in_leaf):\n",
    "    params = {\n",
    "        \"objective\" : \"binary\",\n",
    "        \"metric\" : \"auc\", \n",
    "        'is_unbalance': True,\n",
    "        \"num_leaves\" : int(num_leaves),\n",
    "        \"max_depth\" : int(max_depth),\n",
    "        \"lambda_l2\" : lambda_l2,\n",
    "        \"lambda_l1\" : lambda_l1,\n",
    "        \"num_threads\" : 20,\n",
    "        \"min_child_samples\" : int(min_child_samples),\n",
    "        'min_data_in_leaf': int(min_data_in_leaf),\n",
    "        \"learning_rate\" : 0.03,\n",
    "        \"subsample_freq\" : 5,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    lgtrain = lightgbm.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "    cv_result = lightgbm.cv(params,\n",
    "                       lgtrain,\n",
    "                       1000,\n",
    "                       stratified=True,\n",
    "                       nfold=3)\n",
    "    return cv_result['valid auc-mean'][-1]\n",
    "\n",
    "\n",
    "# Function is now defined and ready for optimization! \n",
    "print(\"LightGBM evaluation function is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJwqBhdeF11Q"
   },
   "source": [
    "Apply the Bayesian optimizer to the function we created in the previous step to identify the best hyperparameters. We will run 5 iterations and set init_points = 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:48:04.682447Z",
     "start_time": "2019-04-22T15:40:14.641634Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JheCOkUE-KZP",
    "outputId": "8f37ee51-885d-44e4-cdcd-ceb7abd58b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.7313   \u001b[39m | \u001b[39m0.04818  \u001b[39m | \u001b[39m0.03175  \u001b[39m | \u001b[39m41.01    \u001b[39m | \u001b[39m5.928e+03\u001b[39m | \u001b[39m1.02e+03 \u001b[39m | \u001b[39m1.976e+03\u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.7443   \u001b[39m | \u001b[35m0.002931 \u001b[39m | \u001b[35m0.02464  \u001b[39m | \u001b[35m29.04    \u001b[39m | \u001b[35m5.12e+03 \u001b[39m | \u001b[35m1.345e+03\u001b[39m | \u001b[35m3.151e+03\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.7055   \u001b[39m | \u001b[39m0.02921  \u001b[39m | \u001b[39m0.005497 \u001b[39m | \u001b[39m36.85    \u001b[39m | \u001b[39m5.98e+03 \u001b[39m | \u001b[39m277.0    \u001b[39m | \u001b[39m1.748e+03\u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.7255   \u001b[39m | \u001b[39m0.03399  \u001b[39m | \u001b[39m0.02158  \u001b[39m | \u001b[39m55.48    \u001b[39m | \u001b[39m7.993e+03\u001b[39m | \u001b[39m1.002e+03\u001b[39m | \u001b[39m2.544e+03\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.7439   \u001b[39m | \u001b[39m0.02759  \u001b[39m | \u001b[39m0.01063  \u001b[39m | \u001b[39m61.67    \u001b[39m | \u001b[39m6.598e+03\u001b[39m | \u001b[39m1.246e+03\u001b[39m | \u001b[39m1.112e+03\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.7027   \u001b[39m | \u001b[39m0.02362  \u001b[39m | \u001b[39m0.02704  \u001b[39m | \u001b[39m12.72    \u001b[39m | \u001b[39m575.8    \u001b[39m | \u001b[39m308.7    \u001b[39m | \u001b[39m1.224e+03\u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7248   \u001b[39m | \u001b[39m0.004654 \u001b[39m | \u001b[39m0.04502  \u001b[39m | \u001b[39m37.58    \u001b[39m | \u001b[39m9.447e+03\u001b[39m | \u001b[39m991.4    \u001b[39m | \u001b[39m1.35e+03 \u001b[39m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (25, 4000),\n",
    "                                                'max_depth': (5, 63),\n",
    "                                                'lambda_l2': (0.0, 0.05),\n",
    "                                                'lambda_l1': (0.0, 0.05),\n",
    "                                                'min_child_samples': (50, 10000),\n",
    "                                                'min_data_in_leaf': (100, 2000)\n",
    "                                                })\n",
    "\n",
    "lgbBO.maximize(n_iter=5, init_points=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rdkxhhST-KZS"
   },
   "source": [
    " **<font color='teal'> Print the best result by using the '.max' function.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:49:01.513767Z",
     "start_time": "2019-04-22T15:49:01.509392Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "oc8z6mfy-KZS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7442844509016954,\n",
       " 'params': {'lambda_l1': 0.0029306655504813817,\n",
       "  'lambda_l2': 0.024639256072447005,\n",
       "  'max_depth': 29.038484757043882,\n",
       "  'min_child_samples': 5120.182434233687,\n",
       "  'min_data_in_leaf': 1344.9519072870098,\n",
       "  'num_leaves': 3150.904931241149}}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation \n",
    "\n",
    "The Bayesian Optimization process has found the best hyperparameters for LightGBM based on AUC score (target = 0.7443)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:50:29.049881Z",
     "start_time": "2019-04-22T15:50:29.045908Z"
    },
    "colab_type": "text",
    "id": "J5LAydKC-KZW"
   },
   "source": [
    "Review the process at each step by using the '.res[0]' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T15:51:01.001688Z",
     "start_time": "2019-04-22T15:51:00.997484Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "X1ttZmrI-KZX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7313452653191486,\n",
       " 'params': {'lambda_l1': 0.048183299383045095,\n",
       "  'lambda_l2': 0.03175387371094503,\n",
       "  'max_depth': 41.01243354277301,\n",
       "  'min_child_samples': 5927.504726192272,\n",
       "  'min_data_in_leaf': 1020.4698618651744,\n",
       "  'num_leaves': 1975.6926610593114}}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation:\n",
    "\n",
    "AUC Score (target): 0.7313\n",
    "\n",
    "Hyperparameters Tested:\n",
    "\n",
    "{\n",
    "  'lambda_l1': 0.04818,\n",
    "  'lambda_l2': 0.03175,\n",
    "  'max_depth': 41,\n",
    "  'min_child_samples': 5927,\n",
    "  'min_data_in_leaf': 1020,\n",
    "  'num_leaves': 1976\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.7313452653191486,\n",
       "  'params': {'lambda_l1': 0.048183299383045095,\n",
       "   'lambda_l2': 0.03175387371094503,\n",
       "   'max_depth': 41.01243354277301,\n",
       "   'min_child_samples': 5927.504726192272,\n",
       "   'min_data_in_leaf': 1020.4698618651744,\n",
       "   'num_leaves': 1975.6926610593114}},\n",
       " {'target': 0.7442844509016954,\n",
       "  'params': {'lambda_l1': 0.0029306655504813817,\n",
       "   'lambda_l2': 0.024639256072447005,\n",
       "   'max_depth': 29.038484757043882,\n",
       "   'min_child_samples': 5120.182434233687,\n",
       "   'min_data_in_leaf': 1344.9519072870098,\n",
       "   'num_leaves': 3150.904931241149}},\n",
       " {'target': 0.7055352919408965,\n",
       "  'params': {'lambda_l1': 0.029205420533006777,\n",
       "   'lambda_l2': 0.005496747090440419,\n",
       "   'max_depth': 36.84502087718671,\n",
       "   'min_child_samples': 5980.315870292989,\n",
       "   'min_data_in_leaf': 277.0365302834856,\n",
       "   'num_leaves': 1748.1393347835933}},\n",
       " {'target': 0.7255393705876799,\n",
       "  'params': {'lambda_l1': 0.03399395278706789,\n",
       "   'lambda_l2': 0.02158403838146125,\n",
       "   'max_depth': 55.48167447108914,\n",
       "   'min_child_samples': 7992.873079750125,\n",
       "   'min_data_in_leaf': 1001.9681671370248,\n",
       "   'num_leaves': 2544.3287910571435}},\n",
       " {'target': 0.7439468190554503,\n",
       "  'params': {'lambda_l1': 0.027591460087483782,\n",
       "   'lambda_l2': 0.0106335588961554,\n",
       "   'max_depth': 61.67398009191161,\n",
       "   'min_child_samples': 6597.691877076441,\n",
       "   'min_data_in_leaf': 1245.9224142496944,\n",
       "   'num_leaves': 1111.6529901038587}},\n",
       " {'target': 0.7026965455180537,\n",
       "  'params': {'lambda_l1': 0.02361930873486557,\n",
       "   'lambda_l2': 0.027043672111214757,\n",
       "   'max_depth': 12.718567460117953,\n",
       "   'min_child_samples': 575.8495782293082,\n",
       "   'min_data_in_leaf': 308.67531726967445,\n",
       "   'num_leaves': 1223.9813097741398}},\n",
       " {'target': 0.7248407169211274,\n",
       "  'params': {'lambda_l1': 0.004653500979928493,\n",
       "   'lambda_l2': 0.04502370587825244,\n",
       "   'max_depth': 37.58095244992967,\n",
       "   'min_child_samples': 9447.143716356315,\n",
       "   'min_data_in_leaf': 991.3981084187595,\n",
       "   'num_leaves': 1349.5219913548028}}]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review all the iterations\n",
    "lgbBO.res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observation:\n",
    "\n",
    "teration\tAUC Score (Target)\t  Better than Previous?\n",
    "1\t                0.7313\t      Initial Random\n",
    "2\t                0.7443\t      Highest AUC (Best)\n",
    "3\t                0.7055\t      Worse than Iteration 2\n",
    "4\t                0.7255\t      Worse than Iteration 2\n",
    "5\t                0.7439\t      Slightly worse than Iteration 2\n",
    "6\t                0.7027\t       Worse than Iteration 2\n",
    "7\t                0.7248\t       Worse than Iteration 2\n",
    "\n",
    "Iteration 2 is considered the best because it has the highest AUC score (target) among all iterations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bayesian_optimization_exercise.ipynb",
   "provenance": []
  },
  "deepnote_execution_queue": [],
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
